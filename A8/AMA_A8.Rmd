---
title: "Interpretability and Explainability in Machine Learning"
author: "Biel Caballero Vergés, Svenja Menzenbach and Kleber Enrique Reyes Illescas"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading libraries, include=FALSE}
library(readxl)
library(ranger)
library(vip)
library(gridExtra)
library(DALEX)
library(DALEXtra)
library(lime)
library(iml)
library(localModel)
# library(fastshap) # Attention! It re-define "explain" from DALEX
if (require(ghostvar)){library(ghostvar)}
library(mgcv)
library(grid)
library(ggplot2)
```

# Data preparation
```{r}
concrete <- as.data.frame(read_excel("Concrete_Data.xls"))
DescVars <- names(concrete)
names(concrete) <- c("Cement","Slag","FlyAsh","Water","Superplast", 
                     "CoarseAggr","FineAggr","Age","Strength")
```

```{r, include=FALSE}
set.seed(42)

concrete_copy <- concrete

sample <- sample(nrow(concrete), 700)
train_set <- concrete_copy[sample,]
test_set <- concrete_copy[-sample,]
```

# 1. Fit a Random Forest
a. Compute the Variable Importance by the reduction of the impurity at the splits defined by each variable.
```{r}
model_rf_imp <- ranger(
  Strength ~ .,
  data = train_set, 
  importance='impurity'
)
print(model_rf_imp)

```



b. Compute the Variable Importance by out-of-bag random permutations.
```{r}
model_rf_perm <- ranger(
  Strength ~ .,
  data = train_set, 
  importance='permutation'
)
print(model_rf_perm)
```

Both methods have similar performance (impurity being slightly better)

c. Do a graphical representation of both Variable Importance measures.
```{r}
rf_imp_vip <- vip(model_rf_imp)
rf_perm_vip <- vip(model_rf_perm)
grid.arrange(rf_imp_vip, rf_perm_vip, ncol=2, 
             top="Left: Reduction in impurity at splits. Right: Out-of-bag permutations")
```

Both methods agree on nearly every parameter. Age, cement, water and superplast are unquestionably the four most significant variables.


d. Compute the Variable Importance of each variable by Shapley Values.
```{r}
rf_shapley <- vip(model_rf_imp, method = "shap",
                  pred_wrapper = yhat,
                  train = train_set,  # argument 'train' must be provided
                  newdata = test_set[,-9],
                  num_features = 8)
grid.arrange(rf_imp_vip, rf_perm_vip, rf_shapley,
             ncol=2, nrow=2,
             top="Top left: Impurity. Top right: oob permutations. Bottom left: Shapley values"
            )
```

Shapley's results align with the same trend, reaffirming the most important variables.

# 2. Fit a linear model and a gam model.
a. Summarize, numerically and graphically, the fitted models.
```{r}
lm_strength <- lm(Strength ~ ., data = train_set)
(summ_lm_strength <- summary(lm_strength))
```
```{r}
gam_strength <- gam(Strength ~ s(Cement) + s(Slag) + s(FlyAsh) + s(Water) + 
                        s(Superplast) + s(CoarseAggr) + s(FineAggr) + s(Age), 
                 data = train_set)
(summ_gam_strength <- summary(gam_strength))
```
```{r}
plot(lm_strength)
```
```{r}
plot(gam_strength)
```
```{r}
gam.check(gam_strength)
```



b. Compute the Variable Importance by Shappley values in the linear and gam fitted models. Compare your results with what you have learned before.

```{r}
lm_strength_shapley <- vip(lm_strength, method="shap",
                  pred_wrapper=predict.lm,
                  train=train_set, # train set must be specified
                  newdata=test_set[,-9], 
                  num_features = 8,
                  exact=TRUE)

plot(lm_strength_shapley)
```
```{r}
gam_strength_shapley <- vip(gam_strength, method="shap",
                  pred_wrapper=predict.gam,
                  train=train_set, # train set must be specified
                  newdata=test_set[,-9],
                  num_features = 8,
                  exact=TRUE)

plot(gam_strength_shapley)
```

# 3. Relevance by Ghost Variables
Compute the relevance by ghots variables in the three fitted models.
```{r}
source("relev.ghost.var.R")
Rel_Gh_Var <- relev.ghost.var(model=gam_strength, 
                              newdata = test_set[, -9],
                              y.ts = test_set[, 9],
                              func.model.ghost.var = lm
)
plot.relev.ghost.var(Rel_Gh_Var,n1=500,ncols.plot = 4)

```

# 4. Global Importance Measures and Plots using the library DALEX
a. Compute Variable Importance by Random Permutations
```{r}
explainer_rf <- explain.default(model = model_rf_imp,  
                               data = test_set[, -9],
                               y = test_set[, 9], 
                               label = "Random Forest")
```

b. Do the Partial Dependence Plot for each explanatory variable.
```{r}
PDP_rf <- model_profile(
  explainer=explainer_rf,
  variables = NULL,  # All variables are used
  N = NULL, # All available data are used
  groups = NULL,
  k = NULL,
  center = TRUE,
  type = "partial" #  partial, conditional or accumulated
)

plot(PDP_rf, facet_ncol=2)
```
Cement and Slag show a consistent increase in predicted Strength with higher quantities, implying their positive impact on concrete Strength. FineAggr and FlyAsh on the other hand show a constant decrease. CoarseAggr has a little increase at 1150 so it has a minimum. Age increases strongly at the beginning and converges fast to a certain value. Superplast also increases at the beginning and converges to a certain value but the increase is lower. Water shows a decreasing S-curve with a higher slope at around 175. Age, Cement and Water seem to have the highest impact.

c. Do the Local (or Conditional) Dependence Plot for each explanatory variable.
```{r}
CDP_rf <- model_profile(
  explainer=explainer_rf,
  variables = NULL,  # All variables are used
  N = NULL, # All available data are used
  groups = NULL,
  k = NULL,
  center = TRUE,
  type = "conditional" #  partial, conditional or accumulated
)

plot(CDP_rf, facet_ncol=2)
```
In comparison to the previous plot age decreases a bit after reaching a maximum. Also Superplast continous increasing  after 12. But in general the plots look very similar.


# 5. Local explainers with library DALEX
Choose two instances in the the test set, the prediction for which we want to explain:    
• The data with the lowest value in Strength.     
• The data with the largest value in Strength.    
For these two instances, do the following tasks for the fitted random forest.    

```{r}
lowestStrength = concrete[which.min(concrete$Strength), ]
highestStrength = concrete[which.max(concrete$Strength), ]
```

a. Explain the predictions using SHAP.
```{r}
bd_rf <- predict_parts(explainer = explainer_rf,
                 new_observation = lowestStrength,
                            type = "shap")

bd_rf
plot(bd_rf)
```
This plot shows that the features Age, Cement, Water, Superplast and FineAggr have the biggest impact (negatively).


```{r}
bd_rf <- predict_parts(explainer = explainer_rf,
                 new_observation = highestStrength,
                            type = "shap")

bd_rf
plot(bd_rf)
```
This plot shows that all features have a good contribution towards Strength. Here again Age, Water and Cement have the highest impact but Water is over Cement even though they value es very similar. Also Slag is more significant here.

b. Explain the predictions using Break-down plots.
```{r}
bd_rf <- predict_parts(explainer = explainer_rf,
                 new_observation = lowestStrength,
                            type = "break_down")

bd_rf
plot(bd_rf)
```
Here the plot shows that Age, Cement, Superplast and Water have a significant impact on the Strength. This means that we can focus on optimizing these input variables to achieve the desired Strength.


```{r}
bd_rf <- predict_parts(explainer = explainer_rf,
                 new_observation = highestStrength,
                            type = "break_down")

bd_rf
plot(bd_rf)
```
Here we can see again that age, water and cement are very important.


c. Explain the predictions using LIME.
```{r}
bd_rf <- predict_surrogate(explainer = explainer_rf,
                 new_observation = lowestStrength,
                            type = "localModel")

bd_rf
plot(bd_rf)
```
This plot that Cement, Water, Superplast and FineAggr have the biggest negative impact while Slag the biggest positive impact.


```{r}
bd_rf <- predict_surrogate(explainer = explainer_rf,
                 new_observation = highestStrength,
                            type = "localModel")

bd_rf
plot(bd_rf)
```
The plot shows all having a positive impact, but Cement and Water and Superplast being the top ones.


d. Do the Individual conditional expectation (ICE) plot, or ceteris paribus plot
```{r}
cp_rf <- predict_profile(explainer = explainer_rf,
                 new_observation = lowestStrength)

cp_rf
plot(cp_rf,facet_ncol=2)
```
The plots show that the predicted concrete strength is low when the content of its ingredients is very low as the points of the prediction seem to be the minimum of each curve..


```{r}
cp_rf <- predict_profile(explainer = explainer_rf,
                 new_observation = highestStrength)

cp_rf
plot(cp_rf,facet_ncol=2)
```
The highest strength however is reached by the maximum of each curve.    


e. Plot in one graphic the Individual conditional expectation (ICE) plot for variable Age for eachcase in the test sample. Add the global Partial Depedence Plot.
```{r}
mp_rf <- model_profile(explainer = explainer_rf,
  variables = "Age",
  N = 100,
  type = "partial"
)

plot(mp_rf, geom = "profiles") +  
  ggtitle("Ceteris-paribus and partial-dependence profiles for Age") 
```
The plot shows that the predicted Strength of concrete generally increases with increasing Age, but the relationship is complex and non-linear. The average effect of Age on Strength is positive, but the effect diminishes at higher ages.
